# 基于版本号的 Replica 校验方案：问题分析与替代方案

## 问题确认

你指出的两个问题确实会破坏基于版本号的方案：

### 问题 1：RDMA 读写缺乏顺序性和原子性保证

**问题描述**：
- RDMA Write/Read 操作不保证原子性
- 版本号（前 8 字节）和 payload 的写入/读取可能不是原子的
- 可能观察到不一致的状态：
  - 版本号已更新，但 payload 还是旧数据
  - 或者相反：payload 已更新，但版本号还是旧值

**具体场景**：
```
时间线：
T1: 写入版本号 v2 到 buffer[0:8]
T2: 写入 payload 到 buffer[8:size]  (可能还在进行中)
T3: 客户端读取版本号 → 读到 v2
T4: 客户端读取 payload → 可能读到部分 v1 + 部分 v2 的混合数据
```

这会导致：
- 版本号校验通过（v2 == v2）
- 但实际读到的 payload 可能是**部分写入的、不一致的数据**

### 问题 2：分配器不保证地址对齐和重用

**问题描述**：
- 当 buffer 被释放后，下次分配可能：
  - 从不同的地址开始（不是从原地址开始）
  - 或者从原地址的某个偏移开始
- 前 8 字节的版本号可能属于：
  - 另一个对象（如果新分配从不同地址开始）
  - 或者前一个对象的残留数据（如果新分配有偏移）

**具体场景**：
```
场景 A：新分配从不同地址开始
原对象 A: buffer[0:1000]  (版本号在 buffer[0:8])
释放后，新对象 B 分配: buffer[100:1100]  (版本号应该在 buffer[100:108])
但客户端仍认为版本号在 buffer[0:8]，读到的是对象 A 的旧版本号

场景 B：新分配有偏移
原对象 A: buffer[0:1000]  (版本号在 buffer[0:8])
释放后，新对象 B 分配: buffer[8:1008]  (版本号应该在 buffer[8:16])
但客户端仍认为版本号在 buffer[0:8]，读到的是对象 A 的版本号
```

---

## 为什么这些问题会导致方案失效

### 失效原因 1：无法保证数据一致性

即使版本号校验通过，也无法保证：
- payload 是完整的、一致的
- payload 确实属于这个版本号对应的对象

### 失效原因 2：无法防止地址重用后的脏读

即使分配器重用地址，版本号校验也无法：
- 正确识别新对象（因为版本号位置可能不对应）
- 防止读到前一个对象的残留数据

---

## 替代方案

### 方案 A：基于元数据的一致性检查（推荐）

**核心思想**：不在 buffer 中嵌入版本号，而是在 Master 的元数据中维护版本信息，并通过客户端验证。

#### 设计要点

1. **Master 元数据中的版本号**：
   ```cpp
   struct ObjectMetadata {
       uint64_t version;  // 每次 Put 时递增
       std::vector<Replica> replicas;
       // ...
   };
   ```

2. **Replica Descriptor 包含版本号**：
   ```cpp
   struct ReplicaDescriptor {
       uint64_t version;           // 从 Master 获取的版本号
       uintptr_t buffer_address;
       uint64_t size;
       // ...
   };
   ```

3. **客户端验证机制**：
   - 客户端从 Master 获取 `(address, version)` 对
   - **不读取 buffer 中的版本号**（因为 RDMA 不保证原子性）
   - 而是通过其他方式验证 buffer 的有效性：
     - **方案 A1**：Master 维护一个 `(address, version)` 映射表
     - **方案 A2**：使用 checksum 验证数据完整性
     - **方案 A3**：客户端读取后，向 Master 确认 buffer 是否仍然有效

#### 优点

- ✅ 不依赖 RDMA 的原子性
- ✅ 不依赖分配器的地址对齐
- ✅ 版本号在 Master 端统一管理，更可靠

#### 缺点

- ⚠️ 需要额外的 Master 查询（可能影响性能）
- ⚠️ 仍然无法完全防止"delete 未同步"的问题（这是你接受的语义）

---

### 方案 B：基于消息队列的 Delete 事件持久化

**核心思想**：将 Delete 事件写入消息队列（EDQ/Kafka），确保所有 Master 都能看到。

#### 设计要点

1. **Delete 操作流程**：
   ```
   Client → Master: Remove(key)
   Master:
     1. 标记 metadata 为 deleted
     2. 写入 Delete 事件到消息队列
     3. 返回成功
   ```

2. **Standby Master 同步**：
   - Standby 从消息队列读取 Delete 事件
   - 更新本地 metadata
   - 即使 Primary 崩溃，Standby 也能看到 Delete 事件

3. **Buffer 重用保护**：
   - Master 在分配新 buffer 前，检查该地址是否在"已删除但未清理"列表中
   - 确保不会立即重用刚删除的 buffer

#### 优点

- ✅ 彻底解决 Delete 未同步问题
- ✅ 不依赖 RDMA 原子性
- ✅ 不依赖分配器对齐

#### 缺点

- ⚠️ 需要引入消息队列（增加系统复杂度）
- ⚠️ 可能影响性能（需要等待消息队列确认）

---

### 方案 C：延迟物理删除 + 客户端验证（混合方案）

**核心思想**：结合延迟删除和客户端验证，在性能和安全性之间平衡。

#### 设计要点

1. **Delete 标记（Tombstone）**：
   - Delete 时，Master 只标记 metadata 为 `DELETED`
   - **不立即释放 buffer**
   - 设置一个"延迟删除时间"（如 30 秒）

2. **客户端验证**：
   - 客户端 Get 时，先检查 metadata 状态
   - 如果状态是 `DELETED`，直接返回 `OBJECT_NOT_FOUND`
   - 如果状态是 `ACTIVE`，正常读取

3. **延迟物理删除**：
   - 后台线程定期清理已标记为 `DELETED` 且超过延迟时间的对象
   - 此时才真正释放 buffer

4. **Failover 保护**：
   - Standby 升主后，如果 metadata 中没有 `DELETED` 标记，对象仍然存在
   - 这符合你"允许 delete 丢失"的语义

#### 优点

- ✅ 不依赖 RDMA 原子性
- ✅ 不依赖分配器对齐
- ✅ 实现相对简单
- ✅ 在延迟删除窗口内，完全防止脏读

#### 缺点

- ⚠️ 延迟删除期间，内存不能立即释放（内存效率略低）
- ⚠️ 仍然无法完全防止"delete 未同步"的问题（但这是你接受的语义）

---

### 方案 D：基于 Raft 的强一致性（最彻底但最复杂）

**核心思想**：使用 Raft 协议确保所有操作（包括 Delete）在所有 Master 之间强一致。

#### 设计要点

1. **所有操作通过 Raft**：
   - Put/Delete 操作先写入 Raft log
   - 多数派确认后，才应用到本地状态机
   - 所有 Standby 自动同步 Raft log

2. **完全消除数据丢失**：
   - Delete 操作必须通过 Raft 确认
   - 即使 Primary 崩溃，Standby 也能从 Raft log 恢复

#### 优点

- ✅ 完全解决所有一致性问题
- ✅ 不依赖 RDMA 原子性
- ✅ 不依赖分配器对齐

#### 缺点

- ⚠️ 实现复杂度高
- ⚠️ 性能开销大（需要 Raft 共识）
- ⚠️ 不符合你"允许少量 metadata 丢失"的语义

---

## 推荐方案

基于你的约束（允许少量 metadata 丢失，但绝不读到其他对象的数据），推荐：

### 首选：方案 C（延迟物理删除 + 客户端验证）

**理由**：
1. 实现相对简单，不需要引入消息队列或 Raft
2. 在延迟删除窗口内，完全防止脏读
3. 符合你"允许 delete 丢失"的语义
4. 不依赖 RDMA 原子性或分配器对齐

### 备选：方案 A（基于元数据的一致性检查）

**理由**：
1. 如果延迟删除的窗口不够，可以用这个方案作为补充
2. 通过 Master 端的版本号管理，避免客户端读取 buffer 中的版本号

---

## 总结

你指出的两个问题确实会破坏基于版本号的方案：

1. **RDMA 缺乏原子性** → 无法保证版本号和 payload 的一致性
2. **分配器不保证对齐** → 无法保证版本号位置对应对象边界

**建议放弃"在 buffer 中嵌入版本号"的方案**，改用：
- **延迟物理删除 + 客户端验证**（方案 C）
- 或 **基于元数据的一致性检查**（方案 A）

这两个方案都不依赖 RDMA 原子性或分配器对齐，更适合 Mooncake 的架构。

